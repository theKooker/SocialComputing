{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Social Computing/Social Gaming - Summer 2022\n",
    "\n",
    "# Exercise Sheet 4: Sentiment Analysis in DotA\n",
    "\n",
    "In this exercise we will work with data gathered from the popular MOBA *Defense of the Ancients 2* or short DotA 2, developed by Valve in 2013. If you are unfamiliar with this game, we provide a short introduction that should be enough to make you understand what the tasks demand from you:\n",
    "\n",
    "In Dota 2, two teams of 5 players play against each other on a single map, each team trying to destroy the enemy base, also called the ancient. In order to do this, they try to kill each other, earn gold and experience by killing non player characters called creeps to gain an advantage over the enemy. In every match, players first choose from a pool of 117 different heroes which are roughly divided into 2 groups: Carries, who start out weak and become much stronger once they accumulated a sufficient amount of gold to buy items they need, and supports, who start protect the carries in the early stages of a match, but tend to become less relevant in the later stages. Every team needs a balanced hero selection in order to have a chance of winning, as too many carries will have that team face a disadvantage early on, while too many supports may cause that team to struggle to win the game even once an advantage has been secured early.\n",
    "\n",
    "Psychologically speaking, DotA - or any MOBA for that matter - is an experiment on succesful team formation and cooperation, as 5 strangers meet each other for one match with the same goal, but usually different views on how to achieve it. Its real world equivalent would be any mash-up of people forced to work in a group, the only difference being that usually real-life situations don't involve another group working against them. \n",
    "\n",
    "Needless to say, the nature of the game does provoke negativity at times, and we want to try to predict it. More precisely, we want to find out whether we can infer negative player behavior from modelling the state of a game as a set of values.\n",
    "\n",
    "The .csv files provided for you contain information from 1.500 matches played during December 2016, and are split into 5 tables: \n",
    "\n",
    "- **chat.csv**: this table contains information about what was said in the chat between teams, when it was said and which player said it. We need the 'key', 'time' and 'slot' column as we are only interested in which team the players belong to, not their identities.\n",
    "- **match.csv**: contains information about the game results. We only need the 'radiant_win' column from it, which tells us which team won.\n",
    "- **players.csv**: Detailed statistics for every player. 'kills' and 'deaths' columns are needed as we will need them to determine underperforming players\n",
    "- **player_times.csv**: Among other things the gold accumulated by every player, for every minute of a match, used to calculate the difference in gold earned between these teams.\n",
    "- **player_ratings.csv**: An estimation of a players skill based on his lifetime winrate.  \n",
    "- **labels.csv**: a sample of labeled chat used for the sentiment analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 4.1: Your first sentiment analysis\n",
    "\n",
    "Sentiment analysis, sometimes called opinion mining, is a method to derive information from the text that allows for a classification as neutral,\n",
    " or negative. It is a semi-supervised process, meaning that you need a small set of labeled data to train your machine learning model on in order to use it on another set of unlabeled data. As the model is trained on the labeled set it learns which input to classify as 'positive','neutral' or 'negative'. More subtle differences might only become distinctable for the model with a larger size of the training set, so as a basic rule you could say: The bigger the training set the better the classifier can perform. Some of its many practical applications are the analysis of customer reviews, social media comments or survey responses.\n",
    "\n",
    "**Note:** We will use a random forest classifier in this task.\n",
    "\n",
    "Your task is to **train a model using the labeled data**, then use that model to predict the sentiments of the whole chat. Let us start with the basics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### a) Preparation\n",
    "\n",
    "**Import** the labels and split them into two arrays: the chat itself and the labels.\n",
    "\n",
    "A label is like a review of a single message:  \n",
    "-1 = negative  \n",
    " 0 = neutral   \n",
    " 1 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries needed for sentiment analysis\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('labels.csv')\n",
    "chat_data = df['Chat message'].tolist();\n",
    "labels =  df['Label'].to_list()\n",
    "# TODO: Import \"labels.csv\" and split it into 2 arrays: chat and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### b) How to train your model\n",
    "\n",
    "In this step you will use the chat and labels to **train your random forest classifier**. In order to do so, **create** the random forest classifier, **fit** it and **make a prediction** on the test set.\n",
    "\n",
    "After you are done, print the accuracy score and comment on it.\n",
    "\n",
    "**Hints:**\n",
    "- When creating the classifier, use n_estimators=200, random_state=0 as arguments.\n",
    "- The test should be 20% of the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nourimohameddhia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some words which do not have any valuable classification information. \n",
    "# We will use 'stopwords' to get rid of them.\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9 23  1]\n",
      " [ 1 56  0]\n",
      " [ 0  2  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.27      0.42        33\n",
      "     neutral       0.69      0.98      0.81        57\n",
      "    positive       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.72        95\n",
      "   macro avg       0.78      0.62      0.63        95\n",
      "weighted avg       0.77      0.72      0.67        95\n",
      "\n",
      "0.7157894736842105\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "chat_data = [str (item) for item in chat_data]\n",
    "vectorizer = TfidfVectorizer (max_features=2500, min_df=3, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "chat_data = vectorizer.fit_transform(chat_data).toarray()\n",
    "\n",
    "# TODO: Create the random forest classifier, fit it and make a prediction on the test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(chat_data, labels, test_size=0.2, random_state=0)\n",
    "cls = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "cls.fit(chat_data,labels)\n",
    "predictions = cls.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO: Write your observations here:**\n",
    "The classification report shows us that the precision of the negative samples is 90. That means, that 90% of the labels are negative, which is wrong and this mistake is shown by the recall which is 0.27. This tells us that there many misclassified samples that should not be negative.\n",
    "The training set is not good distributed there too many neutral compared to positives and negatives\n",
    "Thats the reason why the accuracy not that high.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### c) Prediction time:\n",
    "\n",
    "Now you can use the model to **predict the sentiments** for the whole chat. Import the chat and **predict the labels**. You will need to use `vectorizer.transform().toarray()` on your data, but **DO NOT** use `fit()` anywhere! The classifier is already fitted, fitting it again effectively erases all it has learned.\n",
    "\n",
    "**Note:** The chat table is massive. Labelling all of it may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['neutral', 'negative', 'neutral', ..., 'neutral', 'neutral',\n       'neutral'], dtype='<U8')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatData = pd.read_csv(\"chat.csv\")\n",
    "chatData = chatData.fillna('')\n",
    "unlabeled = chatData.iloc[:,1].values\n",
    "\n",
    "# We remove the first 475 entries as they are the ones contained in our labeled training set,\n",
    "# so we will rather use their original hand made labels.\n",
    "unlabeled = unlabeled[475:]\n",
    "unlabeled = vectorizer.transform(unlabeled).toarray()\n",
    "unlabeled_predictions = cls.predict(unlabeled)\n",
    "unlabeled_predictions\n",
    "# TODO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 4.2: Linear regression\n",
    "\n",
    "Linear regression is a technique that tries to find a correlation between a set of input variables x and a dependant variable y. In mathematical terms:\n",
    "\n",
    "$$y = \\alpha + \\beta X + \\epsilon$$\n",
    "\n",
    "where:\n",
    "- $X$ is the predictive vector, containing the (predictive) variables\n",
    "- $\\alpha$ and $\\beta$ are the model's parameters, where $\\alpha$ is the intercept/bias, $\\beta$ the coefficient vector containing coefficients for each predictive variable\n",
    "- and $\\epsilon$ the prediction error.\n",
    "\n",
    "Note that the assumption made is that the relationship is linear. This is a special case of polynomial regression, where we would allow for e.g. squared relationships.\n",
    "\n",
    "Our dependant variable is the negativity in the chat. Therefore we need to convert our labels into numbers first: We will use 0 for neutral, -1 for negative and +1 for positive sentiments. This is, of course, a simplification, as not all negative statements are equally negative. But we need to acknowledge that it is simply impossible to make an accurate distinction without knowing any context. And if we knew that, there would be no point in doing this regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475\n"
     ]
    }
   ],
   "source": [
    "# Convert the labels into values\n",
    "# First we add the hand made labels for the first 475 entries\n",
    "sentiments = []\n",
    "for i in labels:\n",
    "    if i == 'positive':\n",
    "        sentiments.append(1)\n",
    "    elif i == 'negative':\n",
    "        sentiments.append(-1)\n",
    "    else:\n",
    "        sentiments.append(0)\n",
    "print(len(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46744\n"
     ]
    }
   ],
   "source": [
    "# Now we add our predicted labels\n",
    "for i in unlabeled_predictions:\n",
    "    if i == 'positive':\n",
    "        sentiments.append(1)\n",
    "    elif i == 'negative':\n",
    "        sentiments.append(-1)\n",
    "    elif i == 'neutral':\n",
    "        sentiments.append(0)\n",
    "print(len(sentiments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### a) Preparation:\n",
    "\n",
    "**1.** First, we need to **read the .csv files** and group them by `match_id`.\n",
    "\n",
    "**2.** **Create a dataframe** containing all relevant information where each row represents one match. An empty dataframe has already been created for you with all the columns you need to fill. Fill the columns with the following elements:\n",
    "\n",
    "**3.** **Create a list of lists of lists** called `full_chatdata`, with a tuple for each message, with label and team (you can see an example in the comments).\n",
    "\n",
    "**4.** **Create a list** called `goldData` containing the gold advantage for every timestamp of a match (usually every minute).\n",
    "\n",
    "**5.** **Create a list** called `skillTeams` of the skill values for each player in a match, split into two parts, one for each team, called `skillRadiant` and `skillDire`.\n",
    "\n",
    "**6.** **Add an additional column** called `radiant_win` displaying the winning team with a boolean value.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- you can find the labels in the chatData dataframe\n",
    "- use the `slot` column to determine the team. 0 to 4 is for radiant, 5-9 is for dire\n",
    "- There is a column in the match.csv file called `radiant_win` that displays true if team radiant won, false if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            chatData  \\\n0  [[0, dire], [0, radiant], [0, radiant], [-1, d...   \n1  [[0, radiant], [0, radiant], [-1, radiant], [-...   \n2  [[1, dire], [-1, radiant], [1, dire], [-1, rad...   \n3  [[0, dire], [0, radiant], [0, dire], [0, dire]...   \n4  [[0, dire], [0, radiant], [0, radiant], [0, di...   \n\n                                            goldData KDratios  radiant_win  \\\n0  [0, -257, -255, -567, -550, -1037, -1131, -122...      NaN         True   \n1  [0, -480, -583, -964, -573, -821, -937, -1077,...      NaN        False   \n2  [0, 273, 700, 839, 177, 522, -373, -69, -383, ...      NaN        False   \n3  [0, -487, -157, -178, -69, -255, -497, -404, -...      NaN        False   \n4  [0, 333, 240, 515, 1310, 1755, 2044, 2839, 303...      NaN         True   \n\n                                         playerSkill  \n0  [[25.0, 26.232905478885414, 25.0, 27.614504821...  \n1  [[25.0, 29.49660365641969, 25.0, 18.0712795730...  \n2  [[25, 28.02845249486076, 28.02845249486076, 29...  \n3  [[23.856201249857456, 25.0, 25.0, 25, 18.42651...  \n4  [[25.0, 28.47198596887217, 27.645658014236112,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chatData</th>\n      <th>goldData</th>\n      <th>KDratios</th>\n      <th>radiant_win</th>\n      <th>playerSkill</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[0, dire], [0, radiant], [0, radiant], [-1, d...</td>\n      <td>[0, -257, -255, -567, -550, -1037, -1131, -122...</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>[[25.0, 26.232905478885414, 25.0, 27.614504821...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[0, radiant], [0, radiant], [-1, radiant], [-...</td>\n      <td>[0, -480, -583, -964, -573, -821, -937, -1077,...</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>[[25.0, 29.49660365641969, 25.0, 18.0712795730...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[1, dire], [-1, radiant], [1, dire], [-1, rad...</td>\n      <td>[0, 273, 700, 839, 177, 522, -373, -69, -383, ...</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>[[25, 28.02845249486076, 28.02845249486076, 29...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[0, dire], [0, radiant], [0, dire], [0, dire]...</td>\n      <td>[0, -487, -157, -178, -69, -255, -497, -404, -...</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>[[23.856201249857456, 25.0, 25.0, 25, 18.42651...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[0, dire], [0, radiant], [0, radiant], [0, di...</td>\n      <td>[0, 333, 240, 515, 1310, 1755, 2044, 2839, 303...</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>[[25.0, 28.47198596887217, 27.645658014236112,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Read the csv files and group them by match id\n",
    "chatData = pd.read_csv(\"chat.csv\")\n",
    "chatData = chatData.drop(['unit'],axis=1)\n",
    "chatData['label'] = sentiments # We are adding the labels to the chat messages\n",
    "chatData = chatData.groupby('match_id')\n",
    "player_times = pd.read_csv(\"player_time.csv\")\n",
    "player_times = player_times.groupby('match_id')\n",
    "match_info = pd.read_csv(\"match.csv\")\n",
    "radiant_win = match_info['radiant_win']\n",
    "player_skill = pd.read_csv(\"player_ratings.csv\")\n",
    "player_skill = player_skill[['account_id','trueskill_mu']]\n",
    "player_info = pd.read_csv(\"players.csv\")\n",
    "player_info = player_info[['match_id','account_id','kills','deaths']]\n",
    "player_info = player_info.merge(player_skill,'left')\n",
    "player_info = player_info.groupby('match_id')\n",
    "\n",
    "\n",
    "# 2. Create the dataframe\n",
    "dataframe = pd.DataFrame(columns = ['chatData', 'goldData', 'KDratios', 'radiant_win'])\n",
    "\n",
    "# 3.\n",
    "full_chatdata = []\n",
    "\n",
    "for name, group in chatData:\n",
    "    chat_data_line = []\n",
    "    for index,row in group.iterrows():\n",
    "        chat_tuple = []\n",
    "        # TODO: Create a list of lists of lists called full_chatdata, with a tuple for each message, with label and team.\n",
    "        # It should look something like this:\n",
    "        '''\n",
    "        [\n",
    "            [ [0, 'dire'], [0, 'radiant'], [1, 'radiant'] ], \n",
    "            [ [0,'radiant'], [0, 'dire'], [-1, 'dire'], [0, 'dire'], [0, 'radiant'], [1, 'radiant'], [0, 'radiant'] ]\n",
    "        ]\n",
    "        '''\n",
    "        # Hint 1: use the label column to determine the negativity/positivity of the message\n",
    "        # Hint 2: use the 'slot' column to determine the team. 0 to 4 is for radiant, 5-9 is for dire.\n",
    "        label = row['label'];\n",
    "        team = 'radiant' if row['slot'] <= 4 else 'dire'\n",
    "        chat_tuple.append(label)\n",
    "        chat_tuple.append(team)\n",
    "        chat_data_line.append(chat_tuple)\n",
    "    full_chatdata.append(chat_data_line)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "# 4. Create a list containing the gold advantage\n",
    "full_golddata =[]\n",
    "\n",
    "for name,group in player_times:\n",
    "    radiantAdv =[]\n",
    "    for index, row in group.iterrows():\n",
    "        radiantAdv.append((row['gold_t_0']+row['gold_t_1']+row['gold_t_2']+row['gold_t_3']+row['gold_t_4'])-\n",
    "            (row['gold_t_128']+row['gold_t_129']+row['gold_t_130']+row['gold_t_131']+row['gold_t_132']))\n",
    "        \n",
    "    full_golddata.append(radiantAdv)\n",
    "\n",
    "\n",
    "# 5.\n",
    "full_playerinfo = []\n",
    "for name, group in player_info:\n",
    "    playerinfo = []\n",
    "    for index, row in group.iterrows():\n",
    "        skill = []\n",
    "        skill.append(row['trueskill_mu'])\n",
    "        playerinfo.append(skill)\n",
    "    full_playerinfo.append(playerinfo)\n",
    "\n",
    "full_Skill =[]\n",
    "\n",
    "for row in full_playerinfo:\n",
    "    skillTeams = []\n",
    "    skillRadiant =[]\n",
    "    skillDire = []\n",
    "    for i,player in enumerate(row):\n",
    "        skill = player[0]\n",
    "        if pd.isna(skill):\n",
    "            skill = 25\n",
    "        if i <= 4:\n",
    "            skillRadiant.append(skill)\n",
    "        else:\n",
    "            skillDire.append(skill)\n",
    "        if i == 4:\n",
    "            skillTeams.append(skillRadiant)\n",
    "        if i == 9:\n",
    "            skillTeams.append(skillDire)\n",
    "    full_Skill.append(skillTeams)\n",
    "    # TODO: Check if a Skill value is NA. if it is set it to 25\n",
    "    # TODO: Fill the lists for each team with the playerskills\n",
    "    # Hint: For each game the skill should look like the following:\n",
    "    '''[[RadiantPlayer0skill, ... RadiantPlayer4skill],[DirePlayer0skill, ... DirePlayer4skill]]'''\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "dataframe['chatData'] = full_chatdata\n",
    "dataframe['goldData'] = full_golddata\n",
    "dataframe['playerSkill'] = full_Skill\n",
    "dataframe['radiant_win'] = radiant_win\n",
    "\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### b) Per-match analysis:\n",
    "\n",
    "As you may have noticed, the gold variables are gathered every minute, but the chat times are irregular. We could try to group the chat into 60 second timeframes that would correspond with the gold values, but this would be too tedious. Instead, we will simplify this by looking at the game as a whole:\n",
    "\n",
    "**1.** **Compute the average negativity** for each team by iterating over the list of tuples you created in exercise 4.2.3.\n",
    "\n",
    "**2.** Then, **compute the average gold advantage** for each match, and add a column for the gold advantage at the end of a match. The gold advantage at the end of a match is the last value of the list.\n",
    "\n",
    "**3.** **Create a new column** for the difference in negativity between the two teams.\n",
    "\n",
    "**4.** The skill values aren't very useful in the current format. Take the difference of the lowest and highest skilled player  from each team and **create new columns** for the difference. The reasoning behind this is that a high skill difference in a team probably leads to more harassment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                            chatData  \\\n0  [[0, dire], [0, radiant], [0, radiant], [-1, d...   \n1  [[0, radiant], [0, radiant], [-1, radiant], [-...   \n2  [[1, dire], [-1, radiant], [1, dire], [-1, rad...   \n3  [[0, dire], [0, radiant], [0, dire], [0, dire]...   \n4  [[0, dire], [0, radiant], [0, radiant], [0, di...   \n\n                                            goldData KDratios  radiant_win  \\\n0  [0, -257, -255, -567, -550, -1037, -1131, -122...      NaN         True   \n1  [0, -480, -583, -964, -573, -821, -937, -1077,...      NaN        False   \n2  [0, 273, 700, 839, 177, 522, -373, -69, -383, ...      NaN        False   \n3  [0, -487, -157, -178, -69, -255, -497, -404, -...      NaN        False   \n4  [0, 333, 240, 515, 1310, 1755, 2044, 2839, 303...      NaN         True   \n\n                                         playerSkill  toxicityR  toxicityD  \\\n0  [[25.0, 26.232905478885414, 25.0, 27.614504821...  -0.173913  -0.214286   \n1  [[25.0, 29.49660365641969, 25.0, 18.0712795730...  -0.636364  -0.200000   \n2  [[25, 28.02845249486076, 28.02845249486076, 29...  -0.166667   0.047619   \n3  [[23.856201249857456, 25.0, 25.0, 25, 18.42651...   0.272727  -0.071429   \n4  [[25.0, 28.47198596887217, 27.645658014236112,...  -0.333333  -0.500000   \n\n        goldAvg  goldEnd      diff  skillRadiant  skillDir  \n0   5405.651163    22365  0.040373      7.393499  9.774520  \n1  -7245.478261   -35698 -0.436364     11.425324  7.190551  \n2  -4928.145833   -26720 -0.214286      4.355420  0.000000  \n3  -2074.759259    -7919  0.344156      6.573481  7.358907  \n4  13510.088235    41280  0.166667      5.213370  7.190551  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chatData</th>\n      <th>goldData</th>\n      <th>KDratios</th>\n      <th>radiant_win</th>\n      <th>playerSkill</th>\n      <th>toxicityR</th>\n      <th>toxicityD</th>\n      <th>goldAvg</th>\n      <th>goldEnd</th>\n      <th>diff</th>\n      <th>skillRadiant</th>\n      <th>skillDir</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[0, dire], [0, radiant], [0, radiant], [-1, d...</td>\n      <td>[0, -257, -255, -567, -550, -1037, -1131, -122...</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>[[25.0, 26.232905478885414, 25.0, 27.614504821...</td>\n      <td>-0.173913</td>\n      <td>-0.214286</td>\n      <td>5405.651163</td>\n      <td>22365</td>\n      <td>0.040373</td>\n      <td>7.393499</td>\n      <td>9.774520</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[0, radiant], [0, radiant], [-1, radiant], [-...</td>\n      <td>[0, -480, -583, -964, -573, -821, -937, -1077,...</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>[[25.0, 29.49660365641969, 25.0, 18.0712795730...</td>\n      <td>-0.636364</td>\n      <td>-0.200000</td>\n      <td>-7245.478261</td>\n      <td>-35698</td>\n      <td>-0.436364</td>\n      <td>11.425324</td>\n      <td>7.190551</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[1, dire], [-1, radiant], [1, dire], [-1, rad...</td>\n      <td>[0, 273, 700, 839, 177, 522, -373, -69, -383, ...</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>[[25, 28.02845249486076, 28.02845249486076, 29...</td>\n      <td>-0.166667</td>\n      <td>0.047619</td>\n      <td>-4928.145833</td>\n      <td>-26720</td>\n      <td>-0.214286</td>\n      <td>4.355420</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[0, dire], [0, radiant], [0, dire], [0, dire]...</td>\n      <td>[0, -487, -157, -178, -69, -255, -497, -404, -...</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>[[23.856201249857456, 25.0, 25.0, 25, 18.42651...</td>\n      <td>0.272727</td>\n      <td>-0.071429</td>\n      <td>-2074.759259</td>\n      <td>-7919</td>\n      <td>0.344156</td>\n      <td>6.573481</td>\n      <td>7.358907</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[0, dire], [0, radiant], [0, radiant], [0, di...</td>\n      <td>[0, 333, 240, 515, 1310, 1755, 2044, 2839, 303...</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>[[25.0, 28.47198596887217, 27.645658014236112,...</td>\n      <td>-0.333333</td>\n      <td>-0.500000</td>\n      <td>13510.088235</td>\n      <td>41280</td>\n      <td>0.166667</td>\n      <td>5.213370</td>\n      <td>7.190551</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import  svm \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statistics import mean\n",
    "\n",
    "# 1. Average negativity\n",
    "radiantToxicity_full = []\n",
    "direToxicity_full = []\n",
    "\n",
    "for index, row in dataframe.iterrows():\n",
    "    radiantToxicity = 0\n",
    "    direToxicity = 0\n",
    "    # These counters keep of track of the number of messages each team wrote:\n",
    "    radiantcounter = 0\n",
    "    direcounter = 0\n",
    "    for tuples in row['chatData']:\n",
    "        if tuples[1] == 'radiant':\n",
    "            radiantToxicity +=tuples[0]\n",
    "            radiantcounter +=1\n",
    "        else:\n",
    "            direToxicity +=tuples[0]\n",
    "            direcounter +=1\n",
    "    if radiantcounter == 0:\n",
    "        radiantToxicity_full.append(0)\n",
    "    else:\n",
    "        radiantToxicity_full.append(radiantToxicity / radiantcounter)\n",
    "    if direcounter == 0:\n",
    "        direToxicity_full.append(0)\n",
    "    else:\n",
    "        direToxicity_full.append(direToxicity / direcounter)\n",
    "\n",
    "        # TODO: Calculate each team's toxicity by summing all labels of a match.\n",
    "        # Hint: Don't forget to keep count of the number of messages written by each team.\n",
    "\n",
    "        \n",
    "\n",
    "# We add the newly created columns to our dataframe\n",
    "dataframe['toxicityR'] = radiantToxicity_full\n",
    "dataframe['toxicityD'] = direToxicity_full\n",
    "        \n",
    "# 2. Average gold\n",
    "goldAverages = []\n",
    "goldEnd = []\n",
    "for index, row in dataframe.iterrows():\n",
    "    gold_data = row['goldData']\n",
    "    goldAverages.append(sum(gold_data) / len(gold_data))\n",
    "    goldEnd.append(gold_data[-1:][0])\n",
    "    # TODO: Compute the average gold advantage for each match, as well as the gold advantage at the end of the match.\n",
    "    # Hint: The column goldData contains a list with gold advantage per minutes.\n",
    "\n",
    "\n",
    "\n",
    "# 3. Difference in negativity\n",
    "differences = []\n",
    "\n",
    "# TODO: Compute the difference in negativity between the 2 teams.\n",
    "differences = np.array(radiantToxicity_full) - np.array(direToxicity_full)\n",
    "\n",
    "\n",
    "# 4. K/D ratios\n",
    "lowHighSkillRadiant = []\n",
    "lowHighSkillDir = []\n",
    "for index, row in dataframe.iterrows():\n",
    "    lowHighSkillRadiant.append(max(row[\"playerSkill\"][0]) - min(row[\"playerSkill\"][0]))\n",
    "    lowHighSkillDir.append(max(row[\"playerSkill\"][1]) - min(row[\"playerSkill\"][1]))\n",
    "\n",
    "\n",
    "# We add the newly created columns to our dataframe\n",
    "\n",
    "dataframe['goldAvg'] = goldAverages\n",
    "dataframe['goldEnd'] = goldEnd \n",
    "dataframe['diff'] = differences\n",
    "dataframe['skillRadiant'] = lowHighSkillRadiant\n",
    "dataframe['skillDir'] = lowHighSkillDir\n",
    "\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### c) A warm-up regression\n",
    "\n",
    "Before we test our hypothesis of whether or not the state of the game influences player behavior, we will perform a linear regression with only one input variable: The gold advantage. \n",
    "\n",
    "You have probably wondered why we just assume that the gold values would represent the state of a game, whether a team is losing or winning. So far, this has only been a theory, and we should test it, as it would not make sense to use it as a representation for the state of the game in the actual regression model, if it wasn't representative at all.\n",
    "\n",
    "**1.** Once again, **split your data** into a train set and test set, **create a linear regression model**, **fit the data** and **print your score**. Try it two times: Your dependant variable should always be `radiant_win`, your X should be the average gold advantage and the gold advantage at the end. \n",
    "\n",
    "**2.** **Discuss** the score you obtained! What do the results mean for the explanatory power of the gold variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8314000135504211\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# TODO 1:\n",
    "X = dataframe[['goldEnd']] # TODO\n",
    "y = dataframe[['radiant_win']] # TODO\n",
    "\n",
    "# Splitting the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "print(regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 376\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:142\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: '(slice(None, None, None), None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [39]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(y_pred),\u001B[38;5;28mlen\u001B[39m(y_test))\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(X_test, y_test, color \u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mk\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py:2757\u001B[0m, in \u001B[0;36mplot\u001B[0;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2755\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[1;32m   2756\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m-> 2757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2758\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscalex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscalex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaley\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaley\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2759\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1632\u001B[0m, in \u001B[0;36mAxes.plot\u001B[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1391\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[1;32m   1392\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1629\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[1;32m   1630\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1631\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[0;32m-> 1632\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[1;32m   1633\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[1;32m   1634\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:312\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[0;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m    310\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    311\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m--> 312\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:487\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[0;34m(self, tup, kwargs, return_kwargs)\u001B[0m\n\u001B[1;32m    484\u001B[0m         kw[prop_name] \u001B[38;5;241m=\u001B[39m val\n\u001B[1;32m    486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(xy) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m--> 487\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43m_check_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxy\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    488\u001B[0m     y \u001B[38;5;241m=\u001B[39m _check_1d(xy[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    489\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/cbook/__init__.py:1327\u001B[0m, in \u001B[0;36m_check_1d\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   1321\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings(record\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m w:\n\u001B[1;32m   1322\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\n\u001B[1;32m   1323\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malways\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1324\u001B[0m         category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mWarning\u001B[39;00m,\n\u001B[1;32m   1325\u001B[0m         message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSupport for multi-dimensional indexing\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1327\u001B[0m     ndim \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mndim\n\u001B[1;32m   1328\u001B[0m     \u001B[38;5;66;03m# we have definitely hit a pandas index or series object\u001B[39;00m\n\u001B[1;32m   1329\u001B[0m     \u001B[38;5;66;03m# cast to a numpy array.\u001B[39;00m\n\u001B[1;32m   1330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(w) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3628\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3623\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3624\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3625\u001B[0m         \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3626\u001B[0m         \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m         \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m-> 3628\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3629\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m   3631\u001B[0m \u001B[38;5;66;03m# GH#42269\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5637\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   5633\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   5634\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[1;32m   5635\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[1;32m   5636\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[0;32m-> 5637\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m: (slice(None, None, None), None)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "print(len(y_pred),len(y_test))\n",
    "plt.scatter(X_test, y_test, color ='b')\n",
    "plt.plot(X_test, y_pred, color ='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6114517089586304\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# TODO 1:\n",
    "X = dataframe[['goldAvg']] # TODO\n",
    "y = dataframe[['radiant_win']] # TODO\n",
    "\n",
    "# Splitting the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "print(regr.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 376\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:142\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: '(slice(None, None, None), None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [44]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(y_pred),\u001B[38;5;28mlen\u001B[39m(y_test))\n\u001B[1;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(X_test, y_test, color \u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mk\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py:2757\u001B[0m, in \u001B[0;36mplot\u001B[0;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2755\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[1;32m   2756\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m-> 2757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2758\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscalex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscalex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaley\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaley\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2759\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1632\u001B[0m, in \u001B[0;36mAxes.plot\u001B[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1391\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[1;32m   1392\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1629\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[1;32m   1630\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1631\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[0;32m-> 1632\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[1;32m   1633\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[1;32m   1634\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:312\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[0;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m    310\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    311\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m--> 312\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_base.py:487\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[0;34m(self, tup, kwargs, return_kwargs)\u001B[0m\n\u001B[1;32m    484\u001B[0m         kw[prop_name] \u001B[38;5;241m=\u001B[39m val\n\u001B[1;32m    486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(xy) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m--> 487\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43m_check_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxy\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    488\u001B[0m     y \u001B[38;5;241m=\u001B[39m _check_1d(xy[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    489\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/cbook/__init__.py:1327\u001B[0m, in \u001B[0;36m_check_1d\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   1321\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings(record\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m w:\n\u001B[1;32m   1322\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\n\u001B[1;32m   1323\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malways\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1324\u001B[0m         category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mWarning\u001B[39;00m,\n\u001B[1;32m   1325\u001B[0m         message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSupport for multi-dimensional indexing\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1327\u001B[0m     ndim \u001B[38;5;241m=\u001B[39m \u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mndim\n\u001B[1;32m   1328\u001B[0m     \u001B[38;5;66;03m# we have definitely hit a pandas index or series object\u001B[39;00m\n\u001B[1;32m   1329\u001B[0m     \u001B[38;5;66;03m# cast to a numpy array.\u001B[39;00m\n\u001B[1;32m   1330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(w) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3628\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3623\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3624\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3625\u001B[0m         \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3626\u001B[0m         \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m         \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m-> 3628\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3629\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m   3631\u001B[0m \u001B[38;5;66;03m# GH#42269\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5637\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   5633\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   5634\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[1;32m   5635\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[1;32m   5636\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[0;32m-> 5637\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m: (slice(None, None, None), None)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "print(len(y_pred),len(y_test))\n",
    "plt.scatter(X_test, y_test, color ='b')\n",
    "plt.plot(X_test, y_pred, color ='k')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO: Write your observations here:**\n",
    "The regression score is better for goldEnd model. (goldEnv : 0.8314000135504211, goldAvg: 0.0.6114517089586304)\n",
    "The graphs show that a decision boundary can be clearly picked using goldEnd model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### d) Testing our hypothesis\n",
    "\n",
    "Finally, we can do our linear regression. This time, **use the newly created columns from 4.2 b)**. Use the **gold-related data** and the **diffrence in skill for X** , and the **difference in negativity for Y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019126567208765932\n"
     ]
    }
   ],
   "source": [
    "X = dataframe[['goldAvg', 'goldEnd', 'skillRadiant', 'skillDir']]# TODO: gold-related columns, skill-related columns\n",
    "Y = dataframe[['diff']]# TODO: difference in negativity\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "print(regr.score(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### e) Discussion\n",
    "\n",
    "What is the score? What does that number mean? Discuss possible reasons for this result.\n",
    "\n",
    "Higher the score better the classifier.\n",
    "This score is the R2 score: represents how much the dependent variables ara predictable by the independent variable or how much the points  are correctly classified.\n",
    "Using all the features helped the ML model learn it better.\n",
    "the negative words are userful only no, fuck, die, wtf, rude.... So, the model could learn it easily.\n",
    "\n",
    "**Hint:** Take a peek at the labels.csv file and look at some of the most common negative words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TODO: Write your observations here:**\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}